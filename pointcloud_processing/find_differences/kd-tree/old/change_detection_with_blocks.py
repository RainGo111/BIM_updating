"""
åˆ†å—æ£€æµ‹
"""

import numpy as np
import open3d as o3d
from scipy.spatial import cKDTree
from sklearn.cluster import DBSCAN
import time
import os
import warnings
from collections import defaultdict
import concurrent.futures
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional
warnings.filterwarnings('ignore')

@dataclass
class Block:
    id: str
    bounds: np.ndarray  # [min_x, min_y, min_z, max_x, max_y, max_z]
    pc1_indices: List[int]
    pc2_indices: List[int]
    pc1_points: np.ndarray
    pc2_points: np.ndarray
    has_changes: bool = False
    change_score: float = 0.0

@dataclass
class BlockResult:
    block_id: str
    unchanged: np.ndarray
    minor_change: np.ndarray
    moderate_change: np.ndarray
    major_change: np.ndarray
    removed_indices: List[int]
    added_indices: List[int]
    removed_points: np.ndarray
    added_points: np.ndarray
    local_thresholds: Dict
    change_statistics: Dict

class BlockBasedPointCloudDetector:
    
    def __init__(self, 
                 voxel_size=0.02,
                 distance_threshold=0.05,
                 max_points=100000,
                 coarse_grid_size=2.0,      # ç²—åˆ†å—å¤§å°
                 fine_grid_size=0.5,       # ç²¾ç»†åˆ†å—å¤§å°
                 min_points_per_block=30,  # æ¯å—æœ€å°‘ç‚¹æ•°
                 change_threshold=0.1,     # å—å˜åŒ–é˜ˆå€¼
                 overlap_ratio=0.1,        # å—é‡å æ¯”ä¾‹
                 parallel_processing=True): # å¹¶è¡Œå¤„ç†
        
        self.voxel_size = voxel_size
        self.distance_threshold = distance_threshold
        self.max_points = max_points
        self.coarse_grid_size = coarse_grid_size
        self.fine_grid_size = fine_grid_size
        self.min_points_per_block = min_points_per_block
        self.change_threshold = change_threshold
        self.overlap_ratio = overlap_ratio
        self.parallel_processing = parallel_processing
        
        # åŸºç¡€é˜ˆå€¼
        self.base_thresholds = {
            'unchanged': distance_threshold * 0.3,
            'minor_change': distance_threshold * 0.7,
            'moderate_change': distance_threshold * 1.5,
            'major_change': distance_threshold * 2.5,
        }
        
        # æ–°å¢/åˆ é™¤æ£€æµ‹å‚æ•°
        self.addition_params = {
            'search_radius': distance_threshold * 1.5,
            'min_neighbors': 3,
            'density_ratio': 0.4
        }
        
        print(f"åˆå§‹åŒ–åˆ†å—æ£€æµ‹å™¨:")
        print(f"  ç²—åˆ†å—å¤§å°: {coarse_grid_size}m")
        print(f"  ç²¾ç»†åˆ†å—å¤§å°: {fine_grid_size}m")
        print(f"  æœ€å°å—ç‚¹æ•°: {min_points_per_block}")
        print(f"  å¹¶è¡Œå¤„ç†: {parallel_processing}")
    
    def load_and_preprocess(self, pc1_path, pc2_path):
        """åŠ è½½å¹¶é¢„å¤„ç†ç‚¹äº‘"""
        print("=" * 70)
        print("æ­¥éª¤1: åŠ è½½å’Œé¢„å¤„ç†ç‚¹äº‘")
        print("-" * 70)
        
        # åŠ è½½ç‚¹äº‘
        print("åŠ è½½ç‚¹äº‘æ–‡ä»¶...")
        pc1 = o3d.io.read_point_cloud(pc1_path)
        pc2 = o3d.io.read_point_cloud(pc2_path)
        
        print(f"åŸå§‹ç‚¹äº‘è§„æ¨¡:")
        print(f"  PC1: {len(pc1.points):,} ç‚¹")
        print(f"  PC2: {len(pc2.points):,} ç‚¹")
        
        # ä½“ç´ ä¸‹é‡‡æ ·
        print(f"ä½“ç´ ä¸‹é‡‡æ · (size={self.voxel_size}m)...")
        pc1_down = pc1.voxel_down_sample(self.voxel_size)
        pc2_down = pc2.voxel_down_sample(self.voxel_size)
        print(f"  ä¸‹é‡‡æ ·å - PC1: {len(pc1_down.points):,} ç‚¹, PC2: {len(pc2_down.points):,} ç‚¹")
        
        # é™åˆ¶ç‚¹æ•°ï¼ˆå¦‚æœå¿…è¦ï¼‰
        if len(pc1_down.points) > self.max_points:
            print(f"  é™åˆ¶PC1ç‚¹æ•°åˆ° {self.max_points:,}...")
            indices = np.random.choice(len(pc1_down.points), self.max_points, replace=False)
            pc1_down = pc1_down.select_by_index(indices)
            
        if len(pc2_down.points) > self.max_points:
            print(f"  é™åˆ¶PC2ç‚¹æ•°åˆ° {self.max_points:,}...")
            indices = np.random.choice(len(pc2_down.points), self.max_points, replace=False)
            pc2_down = pc2_down.select_by_index(indices)
        
        print(f"æœ€ç»ˆç‚¹æ•° - PC1: {len(pc1_down.points):,}, PC2: {len(pc2_down.points):,}")
        
        return pc1_down, pc2_down
    
    def compute_bounds(self, points1, points2):
        """è®¡ç®—è”åˆè¾¹ç•Œ"""
        all_points = np.vstack([points1, points2])
        min_coords = np.min(all_points, axis=0)
        max_coords = np.max(all_points, axis=0)
        return min_coords, max_coords
    
    def create_coarse_blocks(self, points1, points2):
        """åˆ›å»ºç²—åˆ†å—"""
        print("\nåˆ›å»ºç²—åˆ†å—...")
        
        min_coords, max_coords = self.compute_bounds(points1, points2)
        
        # è®¡ç®—ç½‘æ ¼ç»´åº¦
        grid_dims = np.ceil((max_coords - min_coords) / self.coarse_grid_size).astype(int)
        print(f"  ç²—ç½‘æ ¼ç»´åº¦: {grid_dims}")
        
        coarse_blocks = []
        block_count = 0
        
        # éå†æ‰€æœ‰ç½‘æ ¼å•å…ƒ
        for i in range(grid_dims[0]):
            for j in range(grid_dims[1]):
                for k in range(grid_dims[2]):
                    # è®¡ç®—å—è¾¹ç•Œ
                    block_min = min_coords + np.array([i, j, k]) * self.coarse_grid_size
                    block_max = block_min + self.coarse_grid_size
                    
                    # æ·»åŠ é‡å 
                    overlap = self.coarse_grid_size * self.overlap_ratio
                    block_min_overlap = block_min - overlap
                    block_max_overlap = block_max + overlap
                    
                    # æŸ¥æ‰¾å—å†…çš„ç‚¹
                    pc1_mask = np.all((points1 >= block_min_overlap) & (points1 <= block_max_overlap), axis=1)
                    pc2_mask = np.all((points2 >= block_min_overlap) & (points2 <= block_max_overlap), axis=1)
                    
                    pc1_indices = np.where(pc1_mask)[0]
                    pc2_indices = np.where(pc2_mask)[0]
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç‚¹
                    if len(pc1_indices) >= self.min_points_per_block or len(pc2_indices) >= self.min_points_per_block:
                        block = Block(
                            id=f"coarse_{i}_{j}_{k}",
                            bounds=np.array([*block_min, *block_max]),
                            pc1_indices=pc1_indices.tolist(),
                            pc2_indices=pc2_indices.tolist(),
                            pc1_points=points1[pc1_indices] if len(pc1_indices) > 0 else np.array([]).reshape(0,3),
                            pc2_points=points2[pc2_indices] if len(pc2_indices) > 0 else np.array([]).reshape(0,3)
                        )
                        coarse_blocks.append(block)
                        block_count += 1
        
        print(f"  åˆ›å»ºäº† {block_count} ä¸ªç²—åˆ†å—")
        return coarse_blocks
    
    def quick_block_assessment(self, block):
        # å¦‚æœä¸€ä¸ªå—åªåœ¨ä¸€ä¸ªç‚¹äº‘ä¸­æœ‰ç‚¹ï¼Œè‚¯å®šæœ‰å˜åŒ–
        if len(block.pc1_points) == 0 or len(block.pc2_points) == 0:
            return True, 1.0
        
        # è®¡ç®—ç‚¹æ•°æ¯”ä¾‹
        count_ratio = abs(len(block.pc1_points) - len(block.pc2_points)) / max(len(block.pc1_points), len(block.pc2_points))
        
        # å¿«é€Ÿè·ç¦»æ£€æŸ¥
        if len(block.pc1_points) > 0 and len(block.pc2_points) > 0:
            tree2 = cKDTree(block.pc2_points)
            sample_size = min(100, len(block.pc1_points))  # é‡‡æ ·æ£€æŸ¥
            sample_indices = np.random.choice(len(block.pc1_points), sample_size, replace=False)
            sample_points = block.pc1_points[sample_indices]
            
            distances, _ = tree2.query(sample_points)
            avg_distance = np.mean(distances)
            change_score = max(count_ratio, avg_distance / self.distance_threshold)
        else:
            change_score = count_ratio
        
        has_changes = change_score > self.change_threshold
        return has_changes, change_score
    
    def filter_changed_blocks(self, coarse_blocks):
        """ç­›é€‰æœ‰å˜åŒ–çš„ç²—åˆ†å—"""
        print("ç­›é€‰æœ‰å˜åŒ–çš„ç²—åˆ†å—...")
        
        changed_blocks = []
        total_blocks = len(coarse_blocks)
        
        for block in coarse_blocks:
            has_changes, change_score = self.quick_block_assessment(block)
            block.has_changes = has_changes
            block.change_score = change_score
            
            if has_changes:
                changed_blocks.append(block)
        
        print(f"  {len(changed_blocks)}/{total_blocks} ä¸ªå—æœ‰æ˜¾è‘—å˜åŒ– ({len(changed_blocks)/total_blocks*100:.1f}%)")
        
        return changed_blocks
    
    def create_fine_blocks(self, coarse_block):
        """å°†ç²—åˆ†å—è¿›ä¸€æ­¥ç»†åˆ†"""
        block_min = coarse_block.bounds[:3]
        block_max = coarse_block.bounds[3:]
        
        # è®¡ç®—ç²¾ç»†ç½‘æ ¼ç»´åº¦
        block_size = block_max - block_min
        fine_dims = np.ceil(block_size / self.fine_grid_size).astype(int)
        
        fine_blocks = []
        
        for i in range(fine_dims[0]):
            for j in range(fine_dims[1]):
                for k in range(fine_dims[2]):
                    # è®¡ç®—ç²¾ç»†å—è¾¹ç•Œ
                    fine_min = block_min + np.array([i, j, k]) * self.fine_grid_size
                    fine_max = fine_min + self.fine_grid_size
                    
                    # ç¡®ä¿ä¸è¶…å‡ºç²—åˆ†å—è¾¹ç•Œ
                    fine_min = np.maximum(fine_min, block_min)
                    fine_max = np.minimum(fine_max, block_max)
                    
                    # æŸ¥æ‰¾ç²¾ç»†å—å†…çš„ç‚¹
                    if len(coarse_block.pc1_points) > 0:
                        pc1_mask = np.all((coarse_block.pc1_points >= fine_min) & (coarse_block.pc1_points <= fine_max), axis=1)
                        fine_pc1_indices = np.array(coarse_block.pc1_indices)[pc1_mask]
                        fine_pc1_points = coarse_block.pc1_points[pc1_mask]
                    else:
                        fine_pc1_indices = np.array([])
                        fine_pc1_points = np.array([]).reshape(0,3)
                    
                    if len(coarse_block.pc2_points) > 0:
                        pc2_mask = np.all((coarse_block.pc2_points >= fine_min) & (coarse_block.pc2_points <= fine_max), axis=1)
                        fine_pc2_indices = np.array(coarse_block.pc2_indices)[pc2_mask]
                        fine_pc2_points = coarse_block.pc2_points[pc2_mask]
                    else:
                        fine_pc2_indices = np.array([])
                        fine_pc2_points = np.array([]).reshape(0,3)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„ç‚¹
                    if len(fine_pc1_points) >= 5 or len(fine_pc2_points) >= 5:
                        fine_block = Block(
                            id=f"{coarse_block.id}_fine_{i}_{j}_{k}",
                            bounds=np.array([*fine_min, *fine_max]),
                            pc1_indices=fine_pc1_indices.tolist(),
                            pc2_indices=fine_pc2_indices.tolist(),
                            pc1_points=fine_pc1_points,
                            pc2_points=fine_pc2_points
                        )
                        fine_blocks.append(fine_block)
        
        return fine_blocks
    
    def precise_block_comparison(self, block):
        """å¯¹å•ä¸ªç²¾ç»†å—è¿›è¡Œç²¾ç¡®æ¯”è¾ƒ"""
        # è‡ªé€‚åº”é˜ˆå€¼
        block_size = np.max(block.bounds[3:] - block.bounds[:3])
        size_factor = min(1.5, max(0.5, block_size / self.fine_grid_size))
        
        local_thresholds = {
            'unchanged': self.base_thresholds['unchanged'] * size_factor,
            'minor_change': self.base_thresholds['minor_change'] * size_factor,
            'moderate_change': self.base_thresholds['moderate_change'] * size_factor,
            'major_change': self.base_thresholds['major_change'] * size_factor,
        }
        
        # åˆå§‹åŒ–ç»“æœæ•°ç»„
        unchanged = np.array([], dtype=bool)
        minor_change = np.array([], dtype=bool)
        moderate_change = np.array([], dtype=bool)
        major_change = np.array([], dtype=bool)
        removed_indices = []
        added_indices = []
        removed_points = np.array([]).reshape(0,3)
        added_points = np.array([]).reshape(0,3)
        
        # å¦‚æœå—ä¸­æ²¡æœ‰ç‚¹ï¼Œè·³è¿‡
        if len(block.pc1_points) == 0 and len(block.pc2_points) == 0:
            return BlockResult(
                block_id=block.id,
                unchanged=unchanged, minor_change=minor_change,
                moderate_change=moderate_change, major_change=major_change,
                removed_indices=removed_indices, added_indices=added_indices,
                removed_points=removed_points, added_points=added_points,
                local_thresholds=local_thresholds,
                change_statistics={}
            )
        
        # å¤„ç†åªæœ‰åˆ é™¤çš„æƒ…å†µ
        if len(block.pc2_points) == 0:
            removed_indices = block.pc1_indices
            removed_points = block.pc1_points
            return BlockResult(
                block_id=block.id,
                unchanged=unchanged, minor_change=minor_change,
                moderate_change=moderate_change, major_change=major_change,
                removed_indices=removed_indices, added_indices=added_indices,
                removed_points=removed_points, added_points=added_points,
                local_thresholds=local_thresholds,
                change_statistics={'type': 'all_removed', 'count': len(removed_indices)}
            )
        
        # å¤„ç†åªæœ‰æ–°å¢çš„æƒ…å†µ
        if len(block.pc1_points) == 0:
            added_indices = block.pc2_indices
            added_points = block.pc2_points
            return BlockResult(
                block_id=block.id,
                unchanged=unchanged, minor_change=minor_change,
                moderate_change=moderate_change, major_change=major_change,
                removed_indices=removed_indices, added_indices=added_indices,
                removed_points=removed_points, added_points=added_points,
                local_thresholds=local_thresholds,
                change_statistics={'type': 'all_added', 'count': len(added_indices)}
            )
        
        # æ­£å¸¸æƒ…å†µï¼šä¸¤ä¸ªç‚¹äº‘éƒ½æœ‰ç‚¹
        tree1 = cKDTree(block.pc1_points)
        tree2 = cKDTree(block.pc2_points)
        
        # PC1 -> PC2 è·ç¦»è®¡ç®—
        distances_1to2, _ = tree2.query(block.pc1_points)
        
        # åˆ†ç±»PC1ä¸­çš„ç‚¹
        unchanged = distances_1to2 < local_thresholds['unchanged']
        minor_change = (distances_1to2 >= local_thresholds['unchanged']) & \
                      (distances_1to2 < local_thresholds['minor_change'])
        moderate_change = (distances_1to2 >= local_thresholds['minor_change']) & \
                         (distances_1to2 < local_thresholds['moderate_change'])
        major_change = (distances_1to2 >= local_thresholds['moderate_change']) & \
                      (distances_1to2 < local_thresholds['major_change'])
        
        # è¯†åˆ«åˆ é™¤çš„ç‚¹
        removed_mask = distances_1to2 >= local_thresholds['major_change']
        if np.any(removed_mask):
            removed_local_indices = np.where(removed_mask)[0]
            removed_indices = [block.pc1_indices[i] for i in removed_local_indices]
            removed_points = block.pc1_points[removed_mask]
        
        # è¯†åˆ«æ–°å¢çš„ç‚¹
        distances_2to1, _ = tree1.query(block.pc2_points)
        added_mask = distances_2to1 >= local_thresholds['major_change']
        
        if np.any(added_mask):
            added_local_indices = np.where(added_mask)[0]
            added_indices = [block.pc2_indices[i] for i in added_local_indices]
            added_points = block.pc2_points[added_mask]
        
        # ç»Ÿè®¡ä¿¡æ¯
        change_stats = {
            'unchanged': np.sum(unchanged),
            'minor_change': np.sum(minor_change),
            'moderate_change': np.sum(moderate_change),
            'major_change': np.sum(major_change),
            'removed': len(removed_indices),
            'added': len(added_indices),
            'total_pc1': len(block.pc1_points),
            'total_pc2': len(block.pc2_points)
        }
        
        return BlockResult(
            block_id=block.id,
            unchanged=unchanged, minor_change=minor_change,
            moderate_change=moderate_change, major_change=major_change,
            removed_indices=removed_indices, added_indices=added_indices,
            removed_points=removed_points, added_points=added_points,
            local_thresholds=local_thresholds,
            change_statistics=change_stats
        )
    
    def process_block_batch(self, blocks):
        """æ‰¹é‡å¤„ç†å—"""
        results = []
        for block in blocks:
            fine_blocks = self.create_fine_blocks(block)
            for fine_block in fine_blocks:
                result = self.precise_block_comparison(fine_block)
                results.append(result)
        return results
    
    def detect_differences(self, pc1, pc2):
        """ä¸»è¦çš„åˆ†å—å·®å¼‚æ£€æµ‹æ–¹æ³•"""
        print("\n" + "=" * 70)
        print("æ­¥éª¤2: åˆ†å±‚åˆ†å—å·®å¼‚æ£€æµ‹")
        print("-" * 70)
        
        start_time = time.time()
        
        points1 = np.asarray(pc1.points)
        points2 = np.asarray(pc2.points)
        
        # ç¬¬ä¸€é˜¶æ®µï¼šç²—åˆ†å—
        coarse_blocks = self.create_coarse_blocks(points1, points2)
        
        # ç¬¬äºŒé˜¶æ®µï¼šç­›é€‰æœ‰å˜åŒ–çš„å—
        changed_blocks = self.filter_changed_blocks(coarse_blocks)
        
        # ç¬¬ä¸‰é˜¶æ®µï¼šç²¾ç»†åˆ†å—å’Œè¯¦ç»†æ¯”è¾ƒ
        print("\nåˆ›å»ºç²¾ç»†åˆ†å—å¹¶è¿›è¡Œè¯¦ç»†æ¯”è¾ƒ...")
        
        all_block_results = []
        
        if self.parallel_processing and len(changed_blocks) > 1:
            # å¹¶è¡Œå¤„ç†
            print(f"  ä½¿ç”¨å¹¶è¡Œå¤„ç† {len(changed_blocks)} ä¸ªå˜åŒ–å—...")
            
            batch_size = max(1, len(changed_blocks) // 4)
            block_batches = [changed_blocks[i:i+batch_size] for i in range(0, len(changed_blocks), batch_size)]
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
                future_to_batch = {executor.submit(self.process_block_batch, batch): batch for batch in block_batches}
                
                for future in concurrent.futures.as_completed(future_to_batch):
                    batch_results = future.result()
                    all_block_results.extend(batch_results)
        else:
            # ä¸²è¡Œå¤„ç†
            print(f"  ä¸²è¡Œå¤„ç† {len(changed_blocks)} ä¸ªå˜åŒ–å—...")
            for i, block in enumerate(changed_blocks):
                print(f"    å¤„ç†å— {i+1}/{len(changed_blocks)}: {block.id}")
                fine_blocks = self.create_fine_blocks(block)
                for fine_block in fine_blocks:
                    result = self.precise_block_comparison(fine_block)
                    all_block_results.append(result)
        
        print(f"  å¤„ç†äº† {len(all_block_results)} ä¸ªç²¾ç»†å—")
        
        # ç¬¬å››é˜¶æ®µï¼šåˆå¹¶ç»“æœ
        print("åˆå¹¶å—ç»“æœ...")
        merged_results = self.merge_block_results(points1, points2, all_block_results)
        
        print(f"æ€»å¤„ç†æ—¶é—´: {time.time() - start_time:.2f}ç§’")
        
        return merged_results
    
    def merge_block_results(self, points1, points2, block_results):
        """åˆå¹¶æ‰€æœ‰å—çš„æ£€æµ‹ç»“æœ"""
        total_pc1 = len(points1)
        total_pc2 = len(points2)
        
        print("  æ­£åœ¨æ”¶é›†å—ç»“æœ...")
        
        # ä½¿ç”¨é›†åˆæ¥æ›´é«˜æ•ˆåœ°å¤„ç†é‡å¤ç´¢å¼•
        removed_indices_set = set()
        added_indices_set = set()
        all_removed_points = []
        all_added_points = []
        
        # ç»Ÿè®¡ä¿¡æ¯
        block_statistics = []
        valid_blocks = 0
        
        for i, result in enumerate(block_results):
            if i % 500 == 0:
                print(f"    å¤„ç†å— {i+1}/{len(block_results)}")
            
            # æ”¶é›†åˆ é™¤å’Œæ–°å¢çš„ç´¢å¼•
            if result.removed_indices:
                removed_indices_set.update(result.removed_indices)
            if result.added_indices:
                added_indices_set.update(result.added_indices)
            
            # æ”¶é›†ç‚¹æ•°æ®
            if len(result.removed_points) > 0:
                all_removed_points.append(result.removed_points)
            if len(result.added_points) > 0:
                all_added_points.append(result.added_points)
            
            # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
            if result.change_statistics:
                block_statistics.append(result.change_statistics)
                valid_blocks += 1
        
        print(f"  æœ‰æ•ˆå—æ•°: {valid_blocks}/{len(block_results)}")
        
        # åˆå¹¶ç‚¹æ•°ç»„
        print("  åˆå¹¶åˆ é™¤ç‚¹...")
        if all_removed_points:
            merged_removed_points = np.vstack(all_removed_points)
        else:
            merged_removed_points = np.array([]).reshape(0,3)
            
        print("  åˆå¹¶æ–°å¢ç‚¹...")
        if all_added_points:
            merged_added_points = np.vstack(all_added_points)
        else:
            merged_added_points = np.array([]).reshape(0,3)
        
        # è½¬æ¢é›†åˆä¸ºåˆ—è¡¨
        unique_removed_indices = list(removed_indices_set)
        unique_added_indices = list(added_indices_set)
        
        print("  åˆ›å»ºå…¨å±€åˆ†ç±»æ•°ç»„...")
        # ç®€åŒ–çš„å…¨å±€åˆ†ç±»
        global_removed = np.zeros(total_pc1, dtype=bool)
        if unique_removed_indices:
            valid_removed_indices = [idx for idx in unique_removed_indices if 0 <= idx < total_pc1]
            global_removed[valid_removed_indices] = True
        
        # è®¡ç®—åŸºæœ¬è·ç¦»åˆ†æ
        global_unchanged = np.zeros(total_pc1, dtype=bool)
        global_minor = np.zeros(total_pc1, dtype=bool)
        global_moderate = np.zeros(total_pc1, dtype=bool) 
        global_major = np.zeros(total_pc1, dtype=bool)
        
        # å¯¹æœªåˆ é™¤çš„ç‚¹è¿›è¡Œè·ç¦»åˆ†æ
        print("  è®¡ç®—è·ç¦»åˆ†æ...")
        non_removed_mask = ~global_removed
        non_removed_indices = np.where(non_removed_mask)[0]
        
        if len(non_removed_indices) > 0 and len(points2) > 0:
            tree2 = cKDTree(points2)
            distances = np.full(total_pc1, np.inf)
            
            # åˆ†æ‰¹å¤„ç†
            batch_size = 10000
            for i in range(0, len(non_removed_indices), batch_size):
                batch_indices = non_removed_indices[i:i+batch_size]
                batch_points = points1[batch_indices]
                batch_distances, _ = tree2.query(batch_points)
                distances[batch_indices] = batch_distances
            
            # åˆ†ç±»
            global_unchanged[non_removed_mask] = distances[non_removed_mask] < self.base_thresholds['unchanged']
            global_minor[non_removed_mask] = ((distances[non_removed_mask] >= self.base_thresholds['unchanged']) & 
                                            (distances[non_removed_mask] < self.base_thresholds['minor_change']))
            global_moderate[non_removed_mask] = ((distances[non_removed_mask] >= self.base_thresholds['minor_change']) & 
                                               (distances[non_removed_mask] < self.base_thresholds['moderate_change']))
            global_major[non_removed_mask] = ((distances[non_removed_mask] >= self.base_thresholds['moderate_change']) & 
                                            (distances[non_removed_mask] < self.base_thresholds['major_change']))
        else:
            distances = np.full(total_pc1, np.inf)
            global_unchanged[non_removed_mask] = True
        
        # ç»Ÿè®¡ç»“æœ
        print("\nåˆ†å—æ£€æµ‹ç»Ÿè®¡:")
        print(f"  å¤„ç†çš„å—æ•°: {len(block_results)}")
        print(f"  æœªå˜åŒ–: {np.sum(global_unchanged):,} ({np.sum(global_unchanged)/total_pc1*100:.1f}%)")
        print(f"  è½»å¾®å˜åŒ–: {np.sum(global_minor):,} ({np.sum(global_minor)/total_pc1*100:.1f}%)")
        print(f"  ä¸­ç­‰å˜åŒ–: {np.sum(global_moderate):,} ({np.sum(global_moderate)/total_pc1*100:.1f}%)")
        print(f"  é‡å¤§å˜åŒ–: {np.sum(global_major):,} ({np.sum(global_major)/total_pc1*100:.1f}%)")
        print(f"  å·²åˆ é™¤: {len(unique_removed_indices):,} ({len(unique_removed_indices)/total_pc1*100:.1f}%)")
        print(f"  æ–°å¢ç‚¹: {len(unique_added_indices):,}")
        
        return {
            'distances': distances,
            'unchanged': global_unchanged,
            'minor_change': global_minor,
            'moderate_change': global_moderate,
            'major_change': global_major,
            'removed': global_removed,
            'removed_points': merged_removed_points,
            'new_points': merged_added_points,
            'pc1_points': points1,
            'pc2_points': points2,
            'thresholds': self.base_thresholds,
            'block_results': block_results[:100],  # åªä¿ç•™å‰100ä¸ªå—ç»“æœ
            'block_statistics': block_statistics,
            'unique_removed_indices': unique_removed_indices,
            'unique_added_indices': unique_added_indices,
            'processing_summary': {
                'total_blocks_processed': len(block_results),
                'valid_blocks': valid_blocks,
                'parallel_processing': self.parallel_processing,
                'coarse_grid_size': self.coarse_grid_size,
                'fine_grid_size': self.fine_grid_size
            }
        }
    
    def save_results(self, pc1, pc2, results):
        """ä¿å­˜åˆ†å—æ£€æµ‹ç»“æœ"""
        print("\n" + "=" * 70)
        print("æ­¥éª¤3: ä¿å­˜åˆ†å—æ£€æµ‹ç»“æœ")
        print("-" * 70)
        
        try:
            # 1. ä¿å­˜ä¸»è¦åˆ†ç±»ç»“æœ
            print("åˆ›å»ºä¸»è¦åˆ†ç±»ç‚¹äº‘...")
            pc_result = o3d.geometry.PointCloud()
            pc_result.points = o3d.utility.Vector3dVector(results['pc1_points'])
            
            colors = np.zeros((len(results['pc1_points']), 3))
            colors[results['unchanged']] = [0, 0.8, 0]        # ç»¿è‰²
            colors[results['minor_change']] = [0.5, 1, 0]     # é»„ç»¿
            colors[results['moderate_change']] = [1, 0.8, 0]  # æ©™è‰²
            colors[results['major_change']] = [1, 0, 0]       # çº¢è‰²
            colors[results['removed']] = [0.5, 0, 0.5]        # ç´«è‰²
            
            pc_result.colors = o3d.utility.Vector3dVector(colors)
            
            print("  ä¿å­˜ block_difference_result.ply...")
            o3d.io.write_point_cloud("block_difference_result.ply", pc_result)
            print("  âœ“ å·²ä¿å­˜")
            
            # 2. ä¿å­˜æ–°å¢ç‚¹
            if len(results['new_points']) > 0:
                print(f"åˆ›å»ºæ–°å¢ç‚¹äº‘ ({len(results['new_points'])} ç‚¹)...")
                pc_new = o3d.geometry.PointCloud()
                pc_new.points = o3d.utility.Vector3dVector(results['new_points'])
                pc_new.paint_uniform_color([0, 0.5, 1])  # è“è‰²
                
                print("  ä¿å­˜ block_new_points.ply...")
                o3d.io.write_point_cloud("block_new_points.ply", pc_new)
                print("  âœ“ å·²ä¿å­˜")
            
            # 3. ä¿å­˜åˆ é™¤ç‚¹
            if len(results['removed_points']) > 0:
                print(f"åˆ›å»ºåˆ é™¤ç‚¹äº‘ ({len(results['removed_points'])} ç‚¹)...")
                
                # åˆ†æ‰¹ä¿å­˜å¤§æ–‡ä»¶
                max_points_per_file = 50000
                if len(results['removed_points']) > max_points_per_file:
                    print(f"  ç‚¹æ•°è¾ƒå¤šï¼Œåˆ†æ‰¹ä¿å­˜...")
                    num_batches = (len(results['removed_points']) + max_points_per_file - 1) // max_points_per_file
                    for i in range(num_batches):
                        start_idx = i * max_points_per_file
                        end_idx = min((i + 1) * max_points_per_file, len(results['removed_points']))
                        
                        batch_points = results['removed_points'][start_idx:end_idx]
                        pc_removed_batch = o3d.geometry.PointCloud()
                        pc_removed_batch.points = o3d.utility.Vector3dVector(batch_points)
                        pc_removed_batch.paint_uniform_color([0.7, 0, 0.7])  # ç´«è‰²
                        
                        filename = f"block_removed_points_part{i+1}.ply"
                        print(f"    ä¿å­˜ {filename} ({len(batch_points)} ç‚¹)...")
                        o3d.io.write_point_cloud(filename, pc_removed_batch)
                        print(f"    âœ“ å·²ä¿å­˜")
                else:
                    pc_removed = o3d.geometry.PointCloud()
                    pc_removed.points = o3d.utility.Vector3dVector(results['removed_points'])
                    pc_removed.paint_uniform_color([0.7, 0, 0.7])  # ç´«è‰²
                    
                    print("  ä¿å­˜ block_removed_points.ply...")
                    o3d.io.write_point_cloud("block_removed_points.ply", pc_removed)
                    print("  âœ“ å·²ä¿å­˜")
            
            # 4. ä¿å­˜ç»„åˆç»“æœ
            print("åˆ›å»ºç»„åˆç‚¹äº‘...")
            max_combined_points = 80000
            
            pc1_sample_size = min(len(results['pc1_points']), max_combined_points - len(results['new_points']))
            if pc1_sample_size < len(results['pc1_points']):
                print(f"  é‡‡æ ·PC1ç‚¹äº‘ ({pc1_sample_size}/{len(results['pc1_points'])} ç‚¹)")
                sample_indices = np.random.choice(len(results['pc1_points']), pc1_sample_size, replace=False)
                sampled_pc1_points = results['pc1_points'][sample_indices]
                sampled_colors = colors[sample_indices]
            else:
                sampled_pc1_points = results['pc1_points']
                sampled_colors = colors
            
            all_points = [sampled_pc1_points]
            all_colors = [sampled_colors]
            
            if len(results['new_points']) > 0:
                all_points.append(results['new_points'])
                new_colors = np.tile([0, 0.5, 1], (len(results['new_points']), 1))
                all_colors.append(new_colors)
            
            if all_points:
                combined_points = np.vstack(all_points)
                combined_colors = np.vstack(all_colors)
                
                pc_combined = o3d.geometry.PointCloud()
                pc_combined.points = o3d.utility.Vector3dVector(combined_points)
                pc_combined.colors = o3d.utility.Vector3dVector(combined_colors)
                
                print("  ä¿å­˜ block_difference_combined.ply...")
                o3d.io.write_point_cloud("block_difference_combined.ply", pc_combined)
                print("  âœ“ å·²ä¿å­˜")
            
            return True
            
        except Exception as e:
            print(f"ä¿å­˜æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def generate_report(self, results):
        """ç”Ÿæˆåˆ†å—æ£€æµ‹æŠ¥å‘Š"""
        print("\nç”Ÿæˆåˆ†å—æ£€æµ‹æŠ¥å‘Š...")
        
        try:
            report = []
            report.append("=" * 60)
            report.append("åˆ†å±‚åˆ†å—ç‚¹äº‘å·®å¼‚æ£€æµ‹æŠ¥å‘Š")
            report.append("=" * 60)
            report.append(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
            report.append("")
            
            # åŸºæœ¬ä¿¡æ¯
            total_pc1 = len(results['pc1_points'])
            total_pc2 = len(results['pc2_points'])
            processing_summary = results['processing_summary']
            
            report.append("ç‚¹äº‘è§„æ¨¡:")
            report.append(f"  PC1: {total_pc1:,} ç‚¹")
            report.append(f"  PC2: {total_pc2:,} ç‚¹")
            report.append("")
            
            # å¤„ç†å‚æ•°
            report.append("åˆ†å—å‚æ•°:")
            report.append(f"  ç²—åˆ†å—å¤§å°: {processing_summary['coarse_grid_size']}m")
            report.append(f"  ç²¾ç»†åˆ†å—å¤§å°: {processing_summary['fine_grid_size']}m")
            report.append(f"  å¹¶è¡Œå¤„ç†: {'æ˜¯' if processing_summary['parallel_processing'] else 'å¦'}")
            report.append(f"  å¤„ç†çš„å—æ•°: {processing_summary['total_blocks_processed']}")
            report.append("")
            
            # æ•´ä½“å˜åŒ–ç»Ÿè®¡
            report.append("æ•´ä½“å˜åŒ–ç»Ÿè®¡:")
            categories = ['unchanged', 'minor_change', 'moderate_change', 'major_change', 'removed']
            labels = ['æœªå˜åŒ–', 'è½»å¾®å˜åŒ–', 'ä¸­ç­‰å˜åŒ–', 'é‡å¤§å˜åŒ–', 'å·²åˆ é™¤']
            
            for cat, label in zip(categories, labels):
                count = np.sum(results[cat])
                percentage = count / total_pc1 * 100 if total_pc1 > 0 else 0
                report.append(f"  {label}: {count:,} ({percentage:.2f}%)")
            
            report.append(f"  æ–°å¢: {len(results['new_points']):,} ç‚¹")
            report.append("")
            
            # æ£€æµ‹è´¨é‡è¯„ä¼°
            report.append("æ£€æµ‹è´¨é‡è¯„ä¼°:")
            change_ratio = (total_pc1 - np.sum(results['unchanged'])) / total_pc1 if total_pc1 > 0 else 0
            report.append(f"  æ€»ä½“å˜åŒ–ç‡: {change_ratio*100:.1f}%")
            
            if change_ratio < 0.05:
                report.append("  è¯„ä¼°: å˜åŒ–å¾ˆå°‘ï¼Œå»ºè®®ä½¿ç”¨æ›´æ•æ„Ÿçš„å‚æ•°")
            elif change_ratio > 0.5:
                report.append("  è¯„ä¼°: å˜åŒ–å¾ˆå¤šï¼Œå»ºè®®æ£€æŸ¥é…å‡†è´¨é‡æˆ–è°ƒæ•´é˜ˆå€¼")
            else:
                report.append("  è¯„ä¼°: å˜åŒ–ç¨‹åº¦é€‚ä¸­ï¼Œæ£€æµ‹ç»“æœå¯ä¿¡")
            
            report.append("")
            report.append("æ–‡ä»¶è¾“å‡º:")
            report.append("  - block_difference_result.ply (ä¸»è¦åˆ†ç±»ç»“æœ)")
            report.append("  - block_difference_combined.ply (ç»„åˆè§†å›¾)")
            if len(results['new_points']) > 0:
                report.append("  - block_new_points.ply (æ–°å¢ç‚¹)")
            if len(results['removed_points']) > 0:
                if len(results['removed_points']) > 50000:
                    report.append("  - block_removed_points_part*.ply (åˆ é™¤ç‚¹-åˆ†æ‰¹)")
                else:
                    report.append("  - block_removed_points.ply (åˆ é™¤ç‚¹)")
            
            report_text = "\n".join(report)
            
            with open("block_difference_report.txt", "w", encoding="utf-8") as f:
                f.write(report_text)
            
            print("  âœ“ æŠ¥å‘Šå·²ä¿å­˜åˆ° block_difference_report.txt")
            
            return report_text
            
        except Exception as e:
            print(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {e}")
            return None
    
    def run(self, pc1_path, pc2_path):
        """è¿è¡Œå®Œæ•´çš„åˆ†å±‚åˆ†å—å·®å¼‚æ£€æµ‹æµç¨‹"""
        print("\n" + "â–ˆ" * 80)
        print("åˆ†å±‚åˆ†å—ç‚¹äº‘å·®å¼‚æ£€æµ‹ç³»ç»Ÿ")
        print("â–ˆ" * 80)
        
        # æ£€æŸ¥æ–‡ä»¶
        if not os.path.exists(pc1_path):
            print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {pc1_path}")
            return None
        if not os.path.exists(pc2_path):
            print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {pc2_path}")
            return None
        
        print(f"\nè¾“å…¥æ–‡ä»¶:")
        print(f"  PC1 (è®¾è®¡): {pc1_path}")
        print(f"  PC2 (å®é™…): {pc2_path}")
        
        print(f"\nåˆ†å—ç­–ç•¥å‚æ•°:")
        print(f"  ç²—åˆ†å—å¤§å°: {self.coarse_grid_size}m")
        print(f"  ç²¾ç»†åˆ†å—å¤§å°: {self.fine_grid_size}m")
        print(f"  æœ€å°å—ç‚¹æ•°: {self.min_points_per_block}")
        print(f"  å—é‡å æ¯”ä¾‹: {self.overlap_ratio}")
        print(f"  å˜åŒ–æ£€æµ‹é˜ˆå€¼: {self.change_threshold}")
        print(f"  å¹¶è¡Œå¤„ç†: {'å¯ç”¨' if self.parallel_processing else 'ç¦ç”¨'}")
        
        try:
            # 1. åŠ è½½å’Œé¢„å¤„ç†
            pc1, pc2 = self.load_and_preprocess(pc1_path, pc2_path)
            
            # 2. åˆ†å±‚åˆ†å—å·®å¼‚æ£€æµ‹
            results = self.detect_differences(pc1, pc2)
            
            # 3. ä¿å­˜ç»“æœ
            success = self.save_results(pc1, pc2, results)
            
            if success:
                # 4. ç”ŸæˆæŠ¥å‘Š
                self.generate_report(results)
                
                print("\n" + "â–ˆ" * 80)
                print("âœ“ åˆ†å±‚åˆ†å—æ£€æµ‹å®Œæˆï¼")
                print("\næ ¸å¿ƒæ”¹è¿›ç‰¹æ€§:")
                print("  âœ“ ä¸¤é˜¶æ®µåˆ†å—ç­–ç•¥ (ç²—åˆ†å— â†’ ç²¾ç»†åˆ†å—)")
                print("  âœ“ æ™ºèƒ½å˜åŒ–å—ç­›é€‰")
                print("  âœ“ è‡ªé€‚åº”å±€éƒ¨é˜ˆå€¼")
                print("  âœ“ ç²¾ç¡®çš„æ–°å¢/åˆ é™¤æ£€æµ‹")
                print("  âœ“ å¹¶è¡Œå¤„ç†æå‡æ•ˆç‡")
                print("  âœ“ å†…å­˜ä¼˜åŒ–å¤„ç†")
                print("\nç”Ÿæˆçš„æ–‡ä»¶:")
                print("  - block_difference_result.ply (ä¸»è¦åˆ†ç±»ç»“æœ)")
                print("  - block_difference_combined.ply (ç»„åˆè§†å›¾)")
                if len(results['new_points']) > 0:
                    print(f"  - block_new_points.ply (æ–°å¢ç‚¹ - {len(results['new_points'])} ç‚¹)")
                if len(results['removed_points']) > 0:
                    if len(results['removed_points']) > 50000:
                        print(f"  - block_removed_points_part*.ply (åˆ é™¤ç‚¹ - {len(results['removed_points'])} ç‚¹ï¼Œåˆ†æ‰¹ä¿å­˜)")
                    else:
                        print(f"  - block_removed_points.ply (åˆ é™¤ç‚¹ - {len(results['removed_points'])} ç‚¹)")
                print("  - block_difference_report.txt (è¯¦ç»†åˆ†ææŠ¥å‘Š)")
                print("\né¢œè‰²ç¼–ç :")
                print("  ğŸŸ¢ ç»¿è‰² = æœªå˜åŒ–")
                print("  ğŸŸ¡ é»„ç»¿ = è½»å¾®å˜åŒ–") 
                print("  ğŸŸ  æ©™è‰² = ä¸­ç­‰å˜åŒ–")
                print("  ğŸ”´ çº¢è‰² = é‡å¤§å˜åŒ–")
                print("  ğŸŸ£ ç´«è‰² = åˆ é™¤ç‚¹")
                print("  ğŸ”µ è“è‰² = æ–°å¢ç‚¹")
                print("â–ˆ" * 80)
            
            return results
            
        except Exception as e:
            print(f"\né”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None


def main():
    """ä¸»å‡½æ•° - æ ‡å‡†åˆ†å—æ¨¡å¼"""
    
    # åˆ›å»ºåˆ†å±‚åˆ†å—æ£€æµ‹å™¨
    detector = BlockBasedPointCloudDetector(
        voxel_size=0.02,           # ä½“ç´ å¤§å°
        distance_threshold=0.05,   # åŸºç¡€è·ç¦»é˜ˆå€¼
        max_points=100000,         # æœ€å¤§å¤„ç†ç‚¹æ•°
        coarse_grid_size=2.0,      # ç²—åˆ†å—å¤§å° (2ç±³)
        fine_grid_size=0.5,        # ç²¾ç»†åˆ†å—å¤§å° (0.5ç±³)
        min_points_per_block=30,   # æ¯å—æœ€å°‘ç‚¹æ•°
        change_threshold=0.1,      # å—å˜åŒ–é˜ˆå€¼
        overlap_ratio=0.1,         # å—é‡å æ¯”ä¾‹
        parallel_processing=True   # å¯ç”¨å¹¶è¡Œå¤„ç†
    )
    
    # è¿è¡Œæ£€æµ‹
    results = detector.run("as_designed_model.ply", "as_built_model.ply")
    
    return results


def run_high_precision_blocks():
    """é«˜ç²¾åº¦åˆ†å—æ¨¡å¼"""
    print("\nè¿è¡Œé«˜ç²¾åº¦åˆ†å—æ£€æµ‹æ¨¡å¼...")
    
    detector = BlockBasedPointCloudDetector(
        voxel_size=0.01,           # æ›´å°çš„ä½“ç´ 
        distance_threshold=0.02,   # æ›´ä¸¥æ ¼çš„é˜ˆå€¼
        max_points=150000,         # æ›´å¤šç‚¹æ•°
        coarse_grid_size=1.0,      # æ›´å°çš„ç²—åˆ†å— (1ç±³)
        fine_grid_size=0.2,        # æ›´å°çš„ç²¾ç»†åˆ†å— (0.2ç±³)
        min_points_per_block=15,   # æ›´å°‘çš„æœ€å°ç‚¹æ•°è¦æ±‚
        change_threshold=0.05,     # æ›´æ•æ„Ÿçš„å˜åŒ–é˜ˆå€¼
        overlap_ratio=0.15,        # æ›´å¤§çš„é‡å 
        parallel_processing=True
    )
    
    results = detector.run("as_designed_model.ply", "as_built_model.ply")
    
    return results


def run_fast_blocks():
    """å¿«é€Ÿåˆ†å—æ¨¡å¼"""
    print("\nè¿è¡Œå¿«é€Ÿåˆ†å—æ£€æµ‹æ¨¡å¼...")
    
    detector = BlockBasedPointCloudDetector(
        voxel_size=0.05,           # è¾ƒå¤§çš„ä½“ç´ 
        distance_threshold=0.1,    # å®½æ¾çš„é˜ˆå€¼
        max_points=50000,          # è¾ƒå°‘ç‚¹æ•°
        coarse_grid_size=3.0,      # è¾ƒå¤§çš„ç²—åˆ†å— (3ç±³)
        fine_grid_size=1.0,        # è¾ƒå¤§çš„ç²¾ç»†åˆ†å— (1ç±³)
        min_points_per_block=50,   # æ›´å¤šçš„æœ€å°ç‚¹æ•°è¦æ±‚
        change_threshold=0.2,      # è¾ƒä¸æ•æ„Ÿçš„å˜åŒ–é˜ˆå€¼
        overlap_ratio=0.05,        # è¾ƒå°çš„é‡å 
        parallel_processing=True
    )
    
    results = detector.run("as_designed_model.ply", "as_built_model.ply")
    
    return results


if __name__ == "__main__":
    print("åˆ†å±‚åˆ†å—ç‚¹äº‘å·®å¼‚æ£€æµ‹ç³»ç»Ÿ")
    print("é€‰æ‹©æ£€æµ‹æ¨¡å¼:")
    print("1. æ ‡å‡†åˆ†å—æ¨¡å¼ (æ¨è) - å¹³è¡¡ç²¾åº¦å’Œæ•ˆç‡")
    print("2. é«˜ç²¾åº¦åˆ†å—æ¨¡å¼ - æœ€é«˜ç²¾åº¦ä½†è¾ƒæ…¢")  
    print("3. å¿«é€Ÿåˆ†å—æ¨¡å¼ - å¿«é€Ÿé¢„è§ˆ")
    print("=" * 50)
    
    # é»˜è®¤è¿è¡Œæ ‡å‡†æ¨¡å¼
    print("è¿è¡Œæ ‡å‡†åˆ†å—æ¨¡å¼...")
    results = main()
    
    if results:
        print("\nâœ“ æ£€æµ‹å®Œæˆï¼è¯·æŸ¥çœ‹ç”Ÿæˆçš„ .ply æ–‡ä»¶å’ŒæŠ¥å‘Šã€‚")
    else:
        print("\nâœ— æ£€æµ‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
